# 2025 - MSMIN5IN43 - IA probabiliste, th√©orie de jeux et machine learning

Projet p√©dagogique d'exploration des approches d'intelligence artificielle probabilistes, de la th√©orie des jeux et du machine learning pour les √©tudiants de l'EPF.

---

## üìÖ Modalit√©s du projet

### √âch√©ances importantes
- **15 d√©cembre 2025** : Pr√©sentation des sujets propos√©s
- **5 janvier 2026** : Deadline de soumission des projets par Pull Request sur ce d√©p√¥t
- **6 janvier 2026** : Pr√©sentation finale et rendu

### Date de livraison
Le code avec le README devront √™tre livr√©s dans un sous-dossier de ce d√©p√¥t pour chaque groupe 1 jour au plus tard avant la pr√©sentation.

### Taille des groupes
La taille standard d'un groupe est de **3 personnes**.
- Groupes de 2 : tol√©r√© (+1 point bonus potentiel pour la charge)
- Groupes de 4 : tol√©r√© (-1 point malus potentiel pour la dilution)
- Individuel : exceptionnel (+3 points bonus potentiel)

### √âvaluation coll√©giale
L'√©valuation portera sur :
1.  **Pr√©sentation/Communication** : Clart√©, p√©dagogie, qualit√© des slides.
2.  **Contenu th√©orique** : Compr√©hension des enjeux, √©tat de l'art, contexte.
3.  **Contenu technique** : Qualit√© du code, r√©sultats obtenus, d√©mos.
4.  **Organisation/Collaboration** : Activit√© Git, r√©partition du travail.

### Livrables attendus
- **Code source** propre et document√©.
- **README** complet (contexte, installation, usage, r√©sultats).
- **Slides** de la pr√©sentation (PDF ou lien).

---

## üí° Liste des sujets propos√©s

Vous √™tes libres de choisir l'un des sujets ci-dessous ou de proposer un sujet personnel (√† faire valider par les encadrants).
**Technologie libre** : Python (recommand√© pour l'√©cosyst√®me ML), C#/.NET (historique du cours), C++, Julia, etc.

### üé≤ Cat√©gorie 1 : IA Probabiliste & Mod√®les Graphiques

Ces sujets explorent l'incertitude, l'inf√©rence bay√©sienne et la mod√©lisation statistique. Ils demandent une bonne compr√©hension des distributions de probabilit√©s et des graphes de facteurs.

#### 1.1. TrueSkill & Matchmaking (Comp√©tition)
Le classement de joueurs dans les jeux en ligne (Xbox Live, LoL, Chess) est un probl√®me probabiliste complexe. Au-del√† du simple syst√®me ELO, le syst√®me TrueSkill utilise des graphes de facteurs pour mod√©liser l'incertitude sur la comp√©tence de chaque joueur (une gaussienne avec moyenne et variance).
- **Travail attendu** :
    - Impl√©menter un moteur d'inf√©rence (via Expectation Propagation ou Variational Inference) pour mettre √† jour les scores apr√®s chaque match.
    - Visualiser la convergence de l'incertitude (sigma) au fil des parties.
- **Extensions** : G√©rer les √©quipes h√©t√©rog√®nes, le "draw margin" (probabilit√© de nul), ou la dynamique temporelle (un joueur progresse ou r√©gresse).
- **Ressources** :
    - [Papier TrueSkill (Microsoft)](https://www.microsoft.com/en-us/research/project/trueskill-ranking-system/)
    - [TrueSkill 2 (Papier r√©cent)](https://www.microsoft.com/en-us/research/publication/trueskill-2-improved-bayesian-skill-rating-system/)
    - [Chapitre du livre MBML](http://mbmlbook.com/TrueSkill.html)

#### 1.2. Inf√©rence Causale (Causal Inference)
Corr√©lation n'est pas causalit√©. Comment savoir si une promo a *caus√©* une vente ou si c'est juste la saisonnalit√© ?
- **Objectif** : Estimer l'effet causal moyen (ATE) d'une intervention (traitement m√©dical, politique publique) √† partir de donn√©es observationnelles.
- **Outils** : Utiliser **Pyro** ou **DoWhy** pour mod√©liser les contrefactuels.
- **Ressources** :
    - [Tutoriel Causal Inference avec Pyro](https://pyro.ai/examples/intro_long.html)
    - [DoWhy Library](https://microsoft.github.io/dowhy/)

#### 1.3. Marketing Mix Modeling (MMM) Bay√©sien
Un sujet tr√®s demand√© en entreprise : optimiser le budget pub.
- **Probl√®me** : Attribuer les ventes aux diff√©rents canaux (TV, Facebook, Google) sachant qu'il y a des effets de saturation (rendements d√©croissants) et de d√©lai (Adstock).
- **Approche** : Utiliser **PyMC** pour construire un mod√®le hi√©rarchique qui estime ces param√®tres inconnus.
- **Ressources** :
    - [PyMC-Marketing](https://github.com/pymc-labs/pymc-marketing)
    - [Google LightweightMMM](https://github.com/google/lightweight_mmm)

#### 1.4. Bayesian Sports Analytics
Pr√©dire les r√©sultats sportifs mieux que les bookmakers.
- **Objectif** : Mod√©liser la force des √©quipes (attaque/d√©fense) dans un championnat (Foot, NBA) en prenant en compte l'avantage du terrain.
- **Technique** : Mod√®les hi√©rarchiques sous **Stan** (via CmdStanPy ou RStan).
- **Ressources** :
    - [Stan Case Studies: Sports](https://mc-stan.org/users/documentation/case-studies.html)
    - [Baio & Blangiardo (2010) - Hierarchical model for Serie A](https://discovery.ucl.ac.uk/id/eprint/16040/1/16040.pdf)

#### 1.5. Bayesian Neural Networks (BNNs)
Le pont entre le Deep Learning et les Probabilit√©s.
- **Concept** : Au lieu d'avoir des poids fixes, chaque poids du r√©seau de neurones est une distribution de probabilit√©. Cela permet au r√©seau de dire "je ne sais pas" (incertitude √©pist√©mique).
- **Travail attendu** : Impl√©menter un BNN simple sous **Pyro** ou **TyXe** pour la classification d'images et visualiser l'incertitude sur des exemples hors distribution (OOD).
- **Ressources** : [TyXe (Pyro BNNs)](https://github.com/cifkao/tyxe), [Tutoriel Pyro BNN](https://pyro.ai/examples/bnn.html).

#### 1.6. Bio-informatique : Identification de motifs & Sant√©
La biologie regorge de donn√©es bruit√©es o√π les mod√®les probabilistes excellent.
- **Sujet A : Motif Finder (HMM)**.
    - Le probl√®me : Retrouver des patterns cach√©s (ex: sites de liaison de prot√©ines) dans des s√©quences d'ADN longues et bruit√©es.
    - L'approche : Utiliser un Mod√®le de Markov Cach√© (HMM) ou un mod√®le de m√©lange pour s√©parer le signal du bruit de fond.
    - [Tutoriel Motif Finder](https://dotnet.github.io/infer/userguide/Motif%20Finder.html)
- **Sujet B : Compr√©hension de l'asthme**.
    - Le probl√®me : Mod√©liser les relations causales complexes entre g√©n√©tique, environnement et sympt√¥mes.
    - L'approche : Construire un R√©seau Bay√©sien pour effectuer des diagnostics probabilistes et de l'inf√©rence causale.
    - [Chapitre Asthma (MBML)](http://mbmlbook.com/Asthma.html)

#### 1.7. Mod√®les Probabilistes Modernes (Pyro / Gaussian Processes)
Explorez les frameworks probabilistes modernes sous Python qui combinent Deep Learning et Probabilit√©s.
- **Sujet A : Rational Speech Acts (RSA)**.
    - Mod√©liser la pragmatique du langage : comment un locuteur choisit ses mots pour √™tre compris, et comment un auditeur interpr√®te l'ambigu√Øt√© (ironie, hyperbole).
    - Utiliser le framework **Pyro** (bas√© sur PyTorch) pour simuler ces agents r√©cursifs.
    - [Tutoriel Pyro RSA](https://pyro.ai/examples/RSA-implicature.html)
- **Sujet B : Processus Gaussiens (Gaussian Processes)**.
    - Une m√©thode puissante pour la r√©gression non-param√©trique, offrant une estimation de l'incertitude "gratuite". Id√©al pour les donn√©es spatiales (g√©ologie) ou temporelles.
    - Utiliser **GPyTorch** pour passer √† l'√©chelle sur GPU.
    - [Deep Kernel Learning](https://arxiv.org/abs/1511.02222) : Apprendre le noyau (kernel) du GP avec un r√©seau de neurones.

#### 1.8. Physics-Informed Neural Networks (PINNs)
Un domaine en pleine explosion : utiliser le Deep Learning pour r√©soudre des √©quations diff√©rentielles partielles (PDEs) en physique (m√©canique des fluides, chaleur).
- **Concept** : Au lieu d'entra√Æner le r√©seau seulement sur des donn√©es, on ajoute un terme dans la fonction de perte qui p√©nalise le non-respect des √©quations physiques (ex: Navier-Stokes).
- **Travail attendu** : R√©soudre une √©quation simple (ex: Burgers ou Heat Equation) avec un PINN et comparer avec une r√©solution num√©rique classique.
- **Ressources** :
    - [DeepXDE Library](https://deepxde.readthedocs.io/en/latest/)
    - [Papier fondateur PINNs](https://arxiv.org/abs/1711.10561)

---

### ‚ôüÔ∏è Cat√©gorie 2 : Th√©orie des Jeux & Syst√®mes Multi-Agents

Ces sujets traitent de la prise de d√©cision strat√©gique, de la coop√©ration et de la comp√©tition entre agents autonomes.

#### 2.1. Poker AI & Information Imparfaite
Le Poker est le "drosophile" de l'IA en information imparfaite (on ne voit pas les cartes de l'adversaire). C'est un probl√®me bien plus dur que les √âchecs ou le Go.
- **Technique cl√©** : **Counterfactual Regret Minimization (CFR)**. L'agent apprend en minimisant son "regret" d'avoir jou√© une action plut√¥t qu'une autre a posteriori.
- **Travail attendu** :
    - Impl√©menter un algorithme CFR (ou MCCFR) sur une version simplifi√©e du Poker (Leduc Hold'em ou Kuhn Poker).
    - Analyser la strat√©gie obtenue (Nash Equilibrium).
- **Ressources** :
    - [OpenSpiel (DeepMind)](https://github.com/deepmind/open_spiel)
    - [Libratus](https://science.sciencemag.org/content/359/6374/418) et [Pluribus](https://science.sciencemag.org/content/365/6456/885).

#### 2.2. Hanabi AI : Coop√©ration & Theory of Mind
Hanabi est un jeu de cartes coop√©ratif unique o√π l'on voit les cartes des autres mais pas les siennes. Il faut communiquer des indices limit√©s.
- **D√©fi** : L'agent doit mod√©liser ce que les autres savent ("Theory of Mind") et interpr√©ter les indices comme des signaux implicites.
- **Travail attendu** : Entra√Æner un agent RL (ex: Rainbow DQN ou PPO) capable de jouer avec des humains ou d'autres bots.
- **Ressources** :
    - [Hanabi Learning Environment](https://github.com/deepmind/hanabi-learning-environment)
    - [The Hanabi Challenge (Papier)](https://arxiv.org/abs/1902.00506)

#### 2.3. Stratego AI : Bluff & Planification (DeepNash)
Stratego est un jeu de plateau √† information imparfaite (pi√®ces cach√©es) qui n√©cessite du bluff et une planification √† long terme.
- **Technique** : **R-NaD (Regularized Nash Dynamics)**. Une approche sans recherche arborescente (MCTS) qui converge vers un √©quilibre de Nash.
- **Objectif** : Impl√©menter une version simplifi√©e de R-NaD sur un mini-Stratego.
- **Ressources** : [DeepNash (DeepMind)](https://www.deepmind.com/blog/mastering-stratego-the-classic-game-of-imperfect-information).

#### 2.4. Mean Field Games (Jeux √† Champ Moyen)
Comment mod√©liser l'interaction strat√©gique d'une foule immense (ex: traders sur un march√©, banc de poissons) ?
- **Concept** : Au lieu de mod√©liser N agents, on mod√©lise un agent repr√©sentatif face √† une "distribution moyenne" des autres.
- **Approche ML** : Utiliser des r√©seaux de neurones (Neural ODEs) pour r√©soudre les √©quations diff√©rentielles stochastiques coupl√©es (Hamilton-Jacobi-Bellman + Fokker-Planck).
- **Ressources** : [Mean Field Games & ML (Papier)](https://arxiv.org/abs/2003.06069), [Tutoriel MFG](https://github.com/Nathan-Sanglier/M2MO-Mean-Field-Games).

#### 2.5. Deep Learning for Mechanism Design (Ench√®res)
Concevoir des r√®gles √©conomiques (ench√®res) optimales pour maximiser le revenu, via le Deep Learning ("Differentiable Economics").
- **Probl√®me** : Concevoir une ench√®re multi-objets optimale est math√©matiquement impossible analytiquement.
- **Solution** : Entra√Æner un r√©seau de neurones (RegretNet) qui prend en entr√©e les valorisations des acheteurs et sort les allocations et les prix, en maximisant le revenu sous contrainte d'incitation (IC).
- **Ressources** : [Optimal Auctions through Deep Learning](https://arxiv.org/abs/1905.05533), [GitHub RegretNet](https://github.com/srp3/regretnet).

#### 2.6. Th√©orie des Jeux appliqu√©e √† la Sant√© & Biologie
La th√©orie des jeux ne sert pas qu'√† jouer, elle mod√©lise le vivant et la soci√©t√©.
- **Sujet A : √âchange de reins (Kidney Exchange)**.
    - Probl√®me : Des patients ont des donneurs incompatibles. Comment organiser des cha√Ænes d'√©changes crois√©s pour sauver le maximum de vies ?
    - C'est un probl√®me d'optimisation combinatoire et de th√©orie des jeux coop√©ratifs.
    - [Travaux de Tuomas Sandholm](http://www.cs.cmu.edu/~sandholm/)
- **Sujet B : Th√©orie des jeux √©volutionniste**.
    - Mod√©liser pourquoi certains comportements (altruisme, agressivit√©) survivent dans une population.
    - Simuler des dynamiques de type "Hawk-Dove" ou "Rock-Paper-Scissors" dans des populations biologiques.

---

### üß† Cat√©gorie 3 : Machine Learning Avanc√© & Deep Learning

Sujets classiques mais exigeants, n√©cessitant une rigueur m√©thodologique (gestion des donn√©es, m√©triques, validation).

#### 3.1. Trading Algorithmique & Finance Quantitative
La finance quantitative est un terrain de jeu id√©al pour les s√©ries temporelles et le RL.
- **Plateforme** : Utiliser **[QuantConnect](https://www.quantconnect.com/)** (moteur LEAN). C'est une plateforme professionnelle qui permet de backtester des strat√©gies en Python/C# sur des donn√©es historiques de haute qualit√©.
- **Sujets** :
    - **Strat√©gie Alpha** : Cr√©er un algo qui bat le march√© (S&P500) sur 5 ans.
    - **GANs in Finance** : Utiliser des GANs (TimeGAN) pour g√©n√©rer des donn√©es synth√©tiques de march√© et entra√Æner des mod√®les de mani√®re plus robuste.
    - **Sentiment Analysis** : Trader en fonction des news financi√®res (NLP sur titres de presse).

#### 3.2. Vision par Ordinateur : Sant√© & Diagnostic
L'IA pour l'aide au diagnostic m√©dical est un enjeu √©thique et technique majeur.
- **Sujets** :
    - **D√©tection de tumeurs** : Segmentation d'images IRM ou histopathologiques.
    - **Classification de radiographies** : D√©tecter pneumonie/COVID sur des radios thoraciques (Dataset CheXNet).
- **D√©fis** : Travailler avec des donn√©es tr√®s d√©s√©quilibr√©es (peu de cas malades) et fournir des cartes de chaleur (Grad-CAM) pour expliquer la d√©cision au m√©decin.

#### 3.3. NLP Avanc√© : Analyse de Sentiment & Fake News
Le traitement du langage naturel (NLP) a √©t√© r√©volutionn√© par les Transformers.
- **Sujet A : D√©tection de Fake News**.
    - Entra√Æner un mod√®le (BERT/RoBERTa) pour classifier des articles comme fiables ou non, en se basant sur le style, le vocabulaire et la source.
- **Sujet B : Analyse de Sentiment Fine**.
    - Ne pas se limiter √† Positif/N√©gatif. D√©tecter l'ironie, le sarcasme, ou des √©motions sp√©cifiques (col√®re, joie, peur) dans des tweets ou commentaires.
- **Outils** : [HuggingFace Transformers](https://huggingface.co/transformers/), [CamemBERT](https://camembert-model.fr/).

#### 3.4. R√©solution de Captcha par Deep Learning
Un classique de la vision par ordinateur qui combine segmentation et reconnaissance de caract√®res (OCR).
- **Objectif** : Entra√Æner un mod√®le capable de lire des captchas alphanum√©riques bruit√©s.
- **M√©thode** :
    - G√©n√©rer son propre dataset de captchas synth√©tiques.
    - Utiliser un CNN pour l'extraction de features et un RNN (LSTM/GRU) avec CTC loss pour la lecture de s√©quence, ou une approche purement attentionnelle (Vision Transformer).
- **Ressources** : [Kaggle Captcha Dataset](https://www.kaggle.com/codingnirvana/captcha-images).

#### 3.5. Reinforcement Learning (RL) : Contr√¥le & Jeux
Apprendre par essai-erreur dans un environnement dynamique.
- **Sujet** : Apprendre √† un agent √† jouer √† un jeu vid√©o (Snake, Mario, Doom) ou √† contr√¥ler un syst√®me physique (pendule invers√©, atterrisseur lunaire).
- **Algos** : Comparer les performances de PPO (Proximal Policy Optimization), DQN (Deep Q-Network) et SAC (Soft Actor-Critic).
- **Lib** : [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3), [Gymnasium](https://gymnasium.farama.org/).

---

### üöÄ Cat√©gorie 4 : Confidentialit√© & ML (Privacy Preserving ML)

Comment entra√Æner des mod√®les sans voir les donn√©es ? Sujet critique pour la sant√© et la banque (RGPD).

#### 4.1. Chiffrement Homomorphe
Le Saint Graal de la privacy : effectuer des calculs (inf√©rence ML) directement sur des donn√©es chiffr√©es, sans jamais les d√©chiffrer.
- **Travail attendu** : Utiliser une librairie sp√©cialis√©e pour entra√Æner un mod√®le simple (R√©gression, Arbre de d√©cision) qui peut pr√©dire sur des donn√©es chiffr√©es.
- **Ressources** :
    - [Microsoft SEAL](https://github.com/Microsoft/SEAL)
    - [Concrete ML (Zama)](https://github.com/zama-ai/concrete-ml) : Permet de convertir des mod√®les Scikit-learn en √©quivalents chiffr√©s.

#### 4.2. Federated Learning (Apprentissage F√©d√©r√©)
Entra√Æner un mod√®le global sur des donn√©es d√©centralis√©es (ex: t√©l√©phones utilisateurs, h√¥pitaux) sans jamais centraliser les donn√©es brutes.
- **Concept** : Le mod√®le voyage vers les donn√©es, apprend localement, et renvoie uniquement les mises √† jour de poids (gradients) au serveur central.
- **Ressources** : [TensorFlow Federated](https://www.tensorflow.org/federated), [PySyft](https://github.com/OpenMined/PySyft).

---

### üî¨ Cat√©gorie 5 : Recherche & Innovation (2024-2025)

Sujets exploratoires bas√©s sur des publications r√©centes (NeurIPS, ICML). Pour les √©tudiants qui veulent toucher √† la recherche.

#### 5.1. GFlowNets (Generative Flow Networks)
Une nouvelle famille de mod√®les g√©n√©ratifs probabilistes (introduite par Yoshua Bengio) con√ßue pour √©chantillonner des objets composites (mol√©cules, graphes) proportionnellement √† une r√©compense.
- **Application** : D√©couverte de m√©dicaments (g√©n√©rer des mol√©cules valides avec haute affinit√©) ou g√©n√©ration de plans.
- **Travail attendu** : Impl√©menter un GFlowNet simple sur un environnement de grille ou de g√©n√©ration de cha√Ænes de caract√®res.
- **Ressources** : [Tutoriel GFlowNet (Mila)](https://mila.quebec/fr/article/gflownet-tutorial), [TorchGFN Library](https://github.com/GFNOrg/torchgfn).

#### 5.2. Diffusion for Combinatorial Optimization (DIFUSCO)
Utiliser les mod√®les de diffusion (ceux qui g√©n√®rent des images) pour r√©soudre des probl√®mes d'optimisation discr√®te difficiles (NP-hard).
- **Concept** : Transformer le probl√®me du Voyageur de Commerce (TSP) ou du SAT en un probl√®me de d√©bruitage. Le mod√®le apprend √† reconstruire la solution optimale √† partir de bruit.
- **Ressources** : [Papier DIFUSCO](https://arxiv.org/abs/2302.08224), [D√©p√¥t GitHub](https://github.com/zuwang12/DIFUSCO).

#### 5.3. Liquid Neural Networks (LNNs)
Une nouvelle architecture de r√©seaux de neurones inspir√©e du cerveau (C. elegans), capable d'adapter sa dynamique en temps continu.
- **Avantage** : Extr√™mement robuste aux donn√©es bruit√©es et capable de g√©n√©raliser hors distribution (OOD) mieux que les RNNs classiques.
- **Application** : Pilotage de drone, pr√©diction de s√©ries temporelles financi√®res ou m√©dicales.
- **Ressources** : [Liquid Time-constant Networks (GitHub)](https://github.com/raminmh/liquid_time_constant_networks), [Papier Nature Machine Intelligence](https://www.nature.com/articles/s42256-020-00267-3).

#### 5.4. Conformal Prediction (Quantification d'Incertitude)
Comment garantir qu'une pr√©diction est "s√ªre" ? La pr√©diction conforme permet de g√©n√©rer des intervalles de confiance valides math√©matiquement, quel que soit le mod√®le sous-jacent.
- **Travail attendu** : Prendre un mod√®le "bo√Æte noire" (ex: Random Forest ou R√©seau de Neurones) et utiliser la pr√©diction conforme pour transformer ses pr√©dictions ponctuelles en intervalles (ex: "Le prix est entre 10‚Ç¨ et 12‚Ç¨ avec 95% de certitude").
- **Ressources** : [MAPIE (Library Python)](https://github.com/scikit-learn-contrib/MAPIE), [Awesome Conformal Prediction](https://github.com/valeman/awesome-conformal-prediction).

#### 5.5. World Models (DreamerV3)
En Reinforcement Learning, au lieu d'apprendre juste une politique, l'agent apprend un "mod√®le du monde" (comment l'environnement r√©agit) et r√™ve dans ce mod√®le pour s'entra√Æner.
- **Objectif** : Impl√©menter une version simplifi√©e d'un World Model sur un jeu simple (Minigrid ou Atari).
- **Ressources** : [DreamerV3 (Papier)](https://arxiv.org/abs/2301.04104), [D√©p√¥t GitHub](https://github.com/danijar/dreamerv3).

---

## üìö Ressources G√©n√©rales

- **HuggingFace** : Pour les mod√®les et datasets (NLP, CV, Audio).
- **Kaggle** : Pour trouver des datasets propres et des notebooks d'exemple.
- **PapersWithCode** : Pour trouver l'√©tat de l'art sur une t√¢che donn√©e.
- **ArXiv** : Pour les papiers de recherche originaux.

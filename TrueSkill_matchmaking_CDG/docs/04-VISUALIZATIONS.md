# 4. Visualisations et Analyses Graphiques

## ğŸ“Š Vue d'Ensemble

Ce projet gÃ©nÃ¨re **7 types de visualisations** pour analyser TrueSkill sous tous les angles :

1.  Convergence de Î¼ (compÃ©tence)
2. Diminution de Ïƒ (incertitude)
3. Comparaison Avant/AprÃ¨s
4. Heatmap de Matchmaking
5. Comparaison des Classements
6. Intervalles de Confiance
7. Dashboard Complet

---

## 1ï¸âƒ£ Convergence de Î¼ (CompÃ©tence)

### Objectif
DÃ©montrer que TrueSkill **converge vers la vraie compÃ©tence** au fil des matchs. 

### Graphique

![Convergence Î¼](../results/convergence_mu.png)

### Ã‰lÃ©ments Visuels

- **Courbes pleines** : Ã‰volution de Î¼ estimÃ©
- **Lignes pointillÃ©es** : Vraie compÃ©tence (rÃ©fÃ©rence cachÃ©e)
- **LÃ©gende** : Nom du joueur + vraie compÃ©tence

### Code ClÃ©

```python
def plot_skill_convergence(players):
    fig, ax = plt.subplots(figsize=(14, 8))
    
    for player in players:
        # Courbe d'estimation
        ax.plot(player.history_mu, 
                label=f"{player.name} (vrai={player.true_skill:.0f})", 
                linewidth=2.5, marker='o', markersize=3, alpha=0.8)
        
        # Ligne de rÃ©fÃ©rence (vraie compÃ©tence)
        ax.axhline(y=player.true_skill, linestyle='--', alpha=0.4)
    
    ax.set_xlabel('Nombre de matchs', fontsize=14, fontweight='bold')
    ax.set_ylabel('CompÃ©tence estimÃ©e (Î¼)', fontsize=14, fontweight='bold')
    ax.set_title('Convergence de TrueSkill vers la Vraie CompÃ©tence', 
                fontsize=16, fontweight='bold')
    ax.legend(loc='best', fontsize=11)
    ax.grid(alpha=0.3)
```

### InterprÃ©tation

âœ… **Convergence rapide** : AprÃ¨s ~50 matchs, Î¼ est proche de la vraie compÃ©tence  
âœ… **StabilitÃ©** : AprÃ¨s convergence, Î¼ oscille lÃ©gÃ¨rement autour de la vÃ©ritÃ©  
âœ… **DiffÃ©renciation** : Les joueurs forts/faibles sont bien sÃ©parÃ©s  

### MÃ©triques AssociÃ©es

```python
# Erreur moyenne aprÃ¨s N matchs
def calculate_convergence_error(players, n_matches):
    errors = []
    for player in players:
        if len(player.history_mu) > n_matches:
            estimated = player.history_mu[n_matches]
            error = abs(estimated - player.true_skill)
            errors.append(error)
    return np.mean(errors)

# RÃ©sultats typiques
# AprÃ¨s 10 matchs  :  erreur = 5.2
# AprÃ¨s 50 matchs  : erreur = 2.1
# AprÃ¨s 100 matchs : erreur = 1.3
```

---

## 2ï¸âƒ£ Diminution de Ïƒ (Incertitude)

### Objectif
Montrer que l'**incertitude diminue** avec l'expÃ©rience (nombre de matchs).

### Graphique

![Diminution Ïƒ](../results/convergence_sigma.png)

### Ã‰lÃ©ments Visuels

- **Courbes dÃ©croissantes** : Ïƒ de chaque joueur
- **Ligne rouge horizontale** : Ïƒ initial (8.333)
- **Zone verte** (optionnel) : Zone de haute confiance (Ïƒ < 2)

### Code ClÃ©

```python
def plot_uncertainty_decrease(players):
    fig, ax = plt.subplots(figsize=(14, 8))
    
    for player in players: 
        ax.plot(player. history_sigma, 
               label=player.name, linewidth=2.5, 
               marker='o', markersize=3, alpha=0.8)
    
    # RÃ©fÃ©rence Ïƒ initial
    ax.axhline(y=8.333, linestyle=':', color='red', 
              alpha=0.5, linewidth=2, label='Ïƒ initial (8.33)')
    
    # Zone de haute confiance
    ax.axhspan(0, 2, alpha=0.1, color='green', 
              label='Zone de confiance Ã©levÃ©e')
    
    ax.set_xlabel('Nombre de matchs', fontsize=14)
    ax.set_ylabel('Incertitude (Ïƒ)', fontsize=14)
    ax.set_title('Diminution de l\'Incertitude au fil des Matchs', 
                fontsize=16, fontweight='bold')
    ax.legend()
```

### InterprÃ©tation

âœ… **DÃ©croissance monotone** : Ïƒ ne remonte jamais (ou trÃ¨s peu avec Ï„)  
âœ… **Convergence asymptotique** : Ïƒ tend vers ~2. 0 (minimum)  
âœ… **MÃªme rythme pour tous** :  Tous les joueurs gagnent en confiance au mÃªme rythme  

### Loi de DÃ©croissance

```python
# Approximation empirique
Ïƒ(n) â‰ˆ 8.33 Ã— exp(-0.02 Ã— n) + 2.0

# OÃ¹ n = nombre de matchs
```

---

## 3ï¸âƒ£ Comparaison Avant/AprÃ¨s

### Objectif
Visualiser l'**impact dramatique** de la simulation (Ã©tat initial vs final).

### Graphique

![Avant/AprÃ¨s](../results/before_after.png)

### Structure

**Deux sous-graphiques cÃ´te Ã  cÃ´te :**

#### Gauche :  AVANT (SystÃ¨me Aveugle)
- Tous les joueurs Ã  Î¼ = 25
- Grandes barres d'erreur (Â±3Ïƒ = Â±25 points)
- Ã‰toiles rouges = vraie compÃ©tence (cachÃ©e)

#### Droite : APRÃˆS (Convergence)
- Barres bleues = Î¼ estimÃ© (diffÃ©renciÃ©s)
- Petites barres d'erreur (Â±3Ïƒ rÃ©duit)
- Ã‰toiles rouges alignÃ©es avec les barres bleues

### Code ClÃ©

```python
def plot_before_after(players):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))
    
    names = [p.name for p in players]
    true_skills = [p.true_skill for p in players]
    estimated_skills = [p.rating. mu for p in players]
    uncertainties = [p.rating.sigma * 3 for p in players]
    
    x = np.arange(len(players))
    
    # AVANT
    ax1.bar(x, [25]*len(players), width=0.6, 
           label='Estimation initiale (Î¼=25)', color='gray', alpha=0.6)
    ax1.scatter(x, true_skills, color='red', s=300, marker='*', 
               label='Vraie compÃ©tence', zorder=5)
    ax1.errorbar(x, [25]*len(players), yerr=[8.333*3]*len(players), 
                fmt='none', ecolor='black', capsize=8, alpha=0.3)
    ax1.set_title('AVANT :  SystÃ¨me Aveugle', fontsize=16)
    
    # APRÃˆS
    ax2.bar(x, estimated_skills, width=0.6, 
           label='TrueSkill (Î¼)', color='steelblue', alpha=0.8)
    ax2.errorbar(x, estimated_skills, yerr=uncertainties, 
                fmt='none', ecolor='black', capsize=8, alpha=0.5)
    ax2.scatter(x, true_skills, color='red', s=300, marker='*', 
               label='Vraie compÃ©tence', zorder=5)
    ax2.set_title(f'APRÃˆS : {players[0].matches_played} matchs', fontsize=16)
```

### Impact Visuel

**Message fort** : 
> "Le systÃ¨me part dans le noir complet et apprend Ã  distinguer les joueurs !"

---

## 4ï¸âƒ£ Heatmap de Matchmaking

### Objectif
Afficher les **probabilitÃ©s de victoire** et la **qualitÃ© des matchs potentiels**.

### Graphique

![Heatmap](../results/heatmap_matchmaking.png)

### Structure

**Deux heatmaps cÃ´te Ã  cÃ´te :**

#### Gauche :  ProbabilitÃ©s de Victoire
- **Ligne vs Colonne** : P(Joueur_ligne bat Joueur_colonne)
- **Couleurs** : 
  - Vert : ProbabilitÃ© Ã©levÃ©e (joueur ligne favorisÃ©)
  - Jaune : Match Ã©quilibrÃ© (~50%)
  - Rouge : ProbabilitÃ© faible (joueur colonne favorisÃ©)

#### Droite : QualitÃ© des Matchs
- **Valeur** :  Score de 0 (dÃ©sÃ©quilibrÃ©) Ã  1 (parfait)
- **Couleurs** :  Bleu (plus foncÃ© = meilleur match)

### Code ClÃ©

```python
import seaborn as sns
from scipy.stats import norm
from trueskill import quality_1vs1

def plot_matchmaking_heatmap(players):
    n = len(players)
    win_probs = np.zeros((n, n))
    match_quality = np.zeros((n, n))
    
    for i in range(n):
        for j in range(n):
            if i != j:
                # ProbabilitÃ© de victoire
                delta_mu = players[i].rating.mu - players[j].rating.mu
                sum_sigma = players[i].rating.sigma**2 + players[j].rating.sigma**2
                beta = 25/6
                win_probs[i][j] = norm.cdf(delta_mu / np.sqrt(2*beta**2 + sum_sigma))
                
                # QualitÃ© du match
                match_quality[i][j] = quality_1vs1(players[i].rating, players[j].rating)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))
    
    # Heatmap probabilitÃ©s
    sns.heatmap(win_probs, annot=True, fmt='.0%', cmap='RdYlGn',
                xticklabels=[p.name for p in players],
                yticklabels=[p.name for p in players],
                ax=ax1, vmin=0, vmax=1)
    ax1.set_title('ProbabilitÃ©s de Victoire')
    
    # Heatmap qualitÃ©
    sns.heatmap(match_quality, annot=True, fmt='.0%', cmap='Blues',
                xticklabels=[p.name for p in players],
                yticklabels=[p.name for p in players],
                ax=ax2, vmin=0, vmax=1)
    ax2.set_title('QualitÃ© des Matchs (100% = parfait)')
```

### Utilisation Pratique

**Algorithme de matchmaking optimal :**

```python
def find_best_match(players):
    """
    Trouve le match le plus Ã©quilibrÃ©
    """
    best_pair = None
    max_quality = 0
    
    for i in range(len(players)):
        for j in range(i+1, len(players)):
            quality = quality_1vs1(players[i].rating, players[j].rating)
            if quality > max_quality:
                max_quality = quality
                best_pair = (players[i], players[j])
    
    return best_pair, max_quality

# Exemple
p1, p2, quality = find_best_match(players)
print(f"Meilleur match : {p1.name} vs {p2.name} (qualitÃ© = {quality:.0%})")
```

---

## 5ï¸âƒ£ Comparaison des Classements

### Objectif
Comparer le **classement TrueSkill** vs **classement par vraie compÃ©tence**.

### Graphique

![Classement](../results/ranking_comparison.png)

### Ã‰lÃ©ments Visuels

- **Barres bleues** : Classement par TrueSkill (Î¼)
- **Barres corail** : Classement par vraie compÃ©tence
- **Barres d'erreur noires** : Incertitude (Â±3Ïƒ)
- **Annotation** : % de positions correctes

### Code ClÃ©

```python
def plot_ranking_comparison(players):
    sorted_by_ts = sorted(players, key=lambda p: p.rating.mu, reverse=True)
    sorted_by_true = sorted(players, key=lambda p: p.true_skill, reverse=True)
    
    names = [p.name for p in sorted_by_ts]
    mus = [p.rating.mu for p in sorted_by_ts]
    true_skills = [p.true_skill for p in sorted_by_ts]
    sigmas = [p.rating.sigma * 3 for p in sorted_by_ts]
    
    x = np.arange(len(players))
    width = 0.35
    
    fig, ax = plt.subplots(figsize=(14, 8))
    
    ax.bar(x - width/2, mus, width, label='TrueSkill (Î¼)', 
          color='steelblue', alpha=0.8)
    ax.bar(x + width/2, true_skills, width, label='Vraie CompÃ©tence', 
          color='coral', alpha=0.8)
    ax.errorbar(x - width/2, mus, yerr=sigmas, 
               fmt='none', ecolor='black', capsize=5, alpha=0.5)
    
    # Calculer la prÃ©cision
    accuracy = sum(1 for i in range(len(players)) 
                  if sorted_by_ts[i].name == sorted_by_true[i].name) / len(players)
    
    ax.text(0.98, 0.98, f'PrÃ©cision :  {accuracy:.0%}',
           transform=ax.transAxes, fontsize=12,
           bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))
```

### MÃ©triques de PrÃ©cision

```python
# 1. PrÃ©cision exacte (mÃªme rang)
exact_accuracy = sum(positions_match) / total_players

# 2. CorrÃ©lation de Spearman (ordre)
from scipy.stats import spearmanr
correlation, p_value = spearmanr(ts_ranks, true_ranks)

# 3. Top-K accuracy
top3_accuracy = sum(player in top3_ts and player in top3_true) / 3
```

---

## 6ï¸âƒ£ Intervalles de Confiance

### Objectif
Visualiser les **intervalles de confiance** [Î¼ - 3Ïƒ, Î¼ + 3Ïƒ] pour chaque joueur.

### Graphique

![Intervalles](../results/confidence_intervals. png)

### Ã‰lÃ©ments Visuels

- **Barres horizontales bleues** : Intervalle Â±3Ïƒ (99.7% de confiance)
- **Point bleu foncÃ©** : Î¼ estimÃ©
- **Ã‰toile rouge** : Vraie compÃ©tence
- **Classement** : Du meilleur (haut) au moins bon (bas)

### Code ClÃ©

```python
def plot_confidence_intervals(players):
    sorted_players = sorted(players, key=lambda p: p.conservative_rating, reverse=True)
    
    names = [p.name for p in sorted_players]
    mus = [p.rating.mu for p in sorted_players]
    sigmas_3 = [p.rating.sigma * 3 for p in sorted_players]
    true_skills = [p.true_skill for p in sorted_players]
    
    y = np.arange(len(sorted_players))
    
    fig, ax = plt.subplots(figsize=(14, 8))
    
    # Intervalles
    for i, (mu, sigma_3) in enumerate(zip(mus, sigmas_3)):
        ax.barh(i, sigma_3*2, left=mu-sigma_3, height=0.6, 
               color='steelblue', alpha=0.3, edgecolor='darkblue')
        # Point central (Î¼)
        ax.plot(mu, i, 'o', color='darkblue', markersize=10, zorder=3)
    
    # Vraies compÃ©tences
    ax.plot(true_skills, y, '*', color='red', markersize=15, zorder=4)
    
    ax.set_yticks(y)
    ax.set_yticklabels(names)
    ax.set_xlabel('CompÃ©tence')
    ax.set_title('Intervalles de Confiance (Â±3Ïƒ = 99.7%)')
    ax.invert_yaxis()  # Meilleur en haut
```

### InterprÃ©tation

âœ… **Ã‰toiles dans les intervalles** : Le systÃ¨me a bien estimÃ©  
âŒ **Ã‰toiles hors intervalles** : Erreur (rare si convergence complÃ¨te)  
ğŸ“Š **Largeur des intervalles** : Indique la confiance du systÃ¨me  

---

## 7ï¸âƒ£ Dashboard Complet

### Objectif
Vue d'ensemble avec **6 sous-graphiques** sur une seule image.

### Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Convergence Î¼       â”‚ Diminutionâ”‚
â”‚ (grande)            â”‚ Ïƒ         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Classement Final                â”‚
â”‚ (TrueSkill vs Vrai)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Win     â”‚ Matchs  â”‚ Incertitude â”‚
â”‚ Rates   â”‚ JouÃ©s   â”‚ Finale      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Code (SimplifiÃ©)

```python
def plot_all_stats(players):
    fig = plt.figure(figsize=(20, 12))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
    
    # 1. Convergence Î¼ (grande)
    ax1 = fig.add_subplot(gs[0, : 2])
    for p in players:
        ax1.plot(p.history_mu, label=p.name)
    
    # 2. Diminution Ïƒ
    ax2 = fig.add_subplot(gs[0, 2])
    for p in players: 
        ax2.plot(p. history_sigma)
    
    # 3. Classement (toute la largeur)
    ax3 = fig.add_subplot(gs[1, :])
    # ...  barres comparatives
    
    # 4-6. Stats individuelles
    ax4 = fig.add_subplot(gs[2, 0])  # Win rates
    ax5 = fig.add_subplot(gs[2, 1])  # Matchs jouÃ©s
    ax6 = fig.add_subplot(gs[2, 2])  # Incertitude finale
    
    plt.suptitle('TrueSkill - Dashboard Complet', fontsize=20)
```

---

## ğŸ¨ Palette de Couleurs

```python
# Palette utilisÃ©e
COLORS = {
    'trueskill': 'steelblue',
    'elo': 'coral',
    'true_skill': 'red',
    'uncertainty': 'purple',
    'positive': 'green',
    'negative': 'red',
    'neutral': 'gray'
}

# Style Seaborn
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
```

---

## ğŸ“Š GÃ©nÃ©ration Automatique

### Script Complet

```python
from src.visualizer import create_all_visualizations

# AprÃ¨s simulation
create_all_visualizations(players)

# GÃ©nÃ¨re automatiquement les 7 graphiques dans results/
```

### RÃ©sultat

```
results/
â”œâ”€â”€ convergence_mu.png
â”œâ”€â”€ convergence_sigma.png
â”œâ”€â”€ before_after.png
â”œâ”€â”€ heatmap_matchmaking.png
â”œâ”€â”€ ranking_comparison.png
â”œâ”€â”€ confidence_intervals.png
â””â”€â”€ all_stats.png
```

---

## ğŸ“ˆ MÃ©triques CalculÃ©es

| MÃ©trique | Formule | InterprÃ©tation |
|----------|---------|----------------|
| **Erreur de convergence** | `mean(|Î¼ - true_skill|)` | PrÃ©cision de l'estimation |
| **RÃ©duction de Ïƒ** | `(Ïƒ_initial - Ïƒ_final) / Ïƒ_initial` | % d'incertitude rÃ©duite |
| **PrÃ©cision classement** | `correct_positions / total` | % positions exactes |
| **CorrÃ©lation Spearman** | `spearmanr(ts_ranks, true_ranks)` | CorrÃ©lation d'ordre |
| **QualitÃ© moyenne** | `mean(quality_1vs1(all_pairs))` | Ã‰quilibre des matchs |

---

**â†’ Prochaine section : [Comparaison ELO](05-COMPARISON-ELO.md)**

"""
Entra√Ænement d'un agent PPO sur Snake
"""

import sys
import os

# Ajouter le r√©pertoire parent au chemin Python
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import gymnasium as gym
from stable_baselines3 import PPO

# Importer l'environnement personnalis√©
from envs.snake_env import SnakeEnv

os.makedirs("models", exist_ok=True)

print("=" * 60)
print("üöÄ Entra√Ænement PPO sur Snake-v0")
print("=" * 60)

# Cr√©er l'environnement Snake
env = SnakeEnv(grid_size=10, render_mode=None)
print(f"‚úÖ Environnement cr√©√© : Snake-v0")
print(f"   - Grille : 10x10")
print(f"   - Actions : 4 (Haut, Droite, Bas, Gauche)")
print(f"   - Observation : 6 variables (position, pomme, direction, longueur)")

# Cr√©er le mod√®le PPO
model = PPO(
    "MlpPolicy",
    env,
    n_steps=2048,
    batch_size=64,
    n_epochs=10,
    learning_rate=3e-4,
    verbose=1,
    device="cpu"
)

print(f"\n‚úÖ Mod√®le PPO cr√©√©")
print(f"   - Learning rate : 3e-4")
print(f"   - N steps : 2048")
print(f"   - Batch size : 64")

# Entra√Æner
print(f"\n‚è≥ Entra√Ænement en cours... (500,000 timesteps)")
print(f"   Cela devrait prendre environ 10-15 minutes...")
print("-" * 60)

model.learn(total_timesteps=1000000)

# Sauvegarder
model.save("models/ppo_snake")
print("-" * 60)
print(f"\n‚úÖ Entra√Ænement PPO termin√© !")
print(f"   Mod√®le sauvegard√© : models/ppo_snake.zip")

env.close()
print("=" * 60)

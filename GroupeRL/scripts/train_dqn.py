"""
Entra√Ænement d'un agent DQN sur CartPole-v1
"""

import gymnasium as gym
from stable_baselines3 import DQN
import os

# Cr√©er le dossier models s'il n'existe pas
os.makedirs("models", exist_ok=True)

print("=" * 60)
print("üöÄ Entra√Ænement DQN sur CartPole-v1")
print("=" * 60)

# Cr√©er l'environnement
env = gym.make("CartPole-v1")
print(f"‚úÖ Environnement cr√©√© : CartPole-v1")
print(f"   - Espace d'observation : {env.observation_space}")
print(f"   - Espace d'action : {env.action_space}")

# Cr√©er le mod√®le DQN avec les hyperparam√®tres
model = DQN(
    "MlpPolicy",
    env,
    learning_rate=1e-3,         # Taux d'apprentissage
    buffer_size=10000,          # Taille du replay buffer
    learning_starts=1000,       # Commencer √† apprendre apr√®s 1000 steps
    target_update_interval=500, # Mettre √† jour le r√©seau cible
    verbose=1,                  # Afficher les logs
    device="cpu"                # "cuda" si GPU disponible
)

print(f"\n‚úÖ Mod√®le DQN cr√©√© avec les hyperparam√®tres")
print(f"   - Learning rate : 1e-3")
print(f"   - Buffer size : 10000")
print(f"   - Learning starts : 1000")
print(f"   - Target update interval : 500")

# Entra√Æner le mod√®le
print(f"\n‚è≥ Entra√Ænement en cours... (50,000 timesteps)")
print(f"   Cela devrait prendre environ 2-3 minutes...")
print("-" * 60)

model.learn(total_timesteps=50000)

# Sauvegarder le mod√®le
model.save("models/dqn_cartpole")
print("-" * 60)
print(f"\n‚úÖ Entra√Ænement DQN termin√© avec succ√®s !")
print(f"   Mod√®le sauvegard√© : models/dqn_cartpole.zip")

env.close()
print("‚úÖ Environnement ferm√©")
print("=" * 60)

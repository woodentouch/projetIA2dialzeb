"""
Test des 3 agents entraÃ®nÃ©s avec visualisation
"""

import sys
import os
import gymnasium as gym
from stable_baselines3 import PPO, DQN, SAC

# Ajouter le rÃ©pertoire parent au chemin Python
script_dir = os.path.dirname(__file__)
project_dir = os.path.join(script_dir, '..')
models_dir = os.path.join(project_dir, "models")

print("=" * 70)
print("ðŸŽ® TEST DES AGENTS ENTRAÃŽNÃ‰S")
print("=" * 70)

# Test PPO et DQN sur CartPole
print("\nðŸŽ¯ Environnement 1 : CartPole-v1 (PPO et DQN)")
print("-" * 70)

env_cartpole = gym.make("CartPole-v1", render_mode="human")

# Charger les modÃ¨les pour CartPole
models_cartpole = {
    "PPO": PPO.load(os.path.join(models_dir, "ppo_cartpole"), env=env_cartpole),
    "DQN": DQN.load(os.path.join(models_dir, "dqn_cartpole"), env=env_cartpole),
}

for algo_name, model in models_cartpole.items():
    print(f"\nðŸŽ¬ Test de {algo_name} sur CartPole-v1...")
    print(f"   Vous verrez une fenÃªtre avec le jeu !")
    
    # 3 Ã©pisodes de test
    scores = []
    for episode in range(3):
        obs, info = env_cartpole.reset()
        done = False
        total_reward = 0
        steps = 0
        
        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = env_cartpole.step(action)
            done = terminated or truncated
            total_reward += reward
            steps += 1
        
        scores.append(total_reward)
        print(f"   Episode {episode+1}: Score = {total_reward:.0f}, Ã‰tapes = {steps}")
    
    avg_score = sum(scores) / len(scores)
    print(f"   âœ… Score moyen {algo_name} : {avg_score:.1f}")
    print()

env_cartpole.close()

# Test SAC sur Pendulum
print("\nðŸŽ¯ Environnement 2 : Pendulum-v1 (SAC)")
print("-" * 70)

env_pendulum = gym.make("Pendulum-v1", render_mode="human")

model_sac = SAC.load(os.path.join(models_dir, "sac_pendulum"), env=env_pendulum)

print(f"\nðŸŽ¬ Test de SAC sur Pendulum-v1...")
print(f"   Vous verrez une fenÃªtre avec le pendule !")

# 3 Ã©pisodes de test
scores_sac = []
for episode in range(3):
    obs, info = env_pendulum.reset()
    done = False
    total_reward = 0
    steps = 0
    
    while not done:
        action, _ = model_sac.predict(obs, deterministic=True)
        obs, reward, terminated, truncated, info = env_pendulum.step(action)
        done = terminated or truncated
        total_reward += reward
        steps += 1
    
    scores_sac.append(total_reward)
    print(f"   Episode {episode+1}: Score = {total_reward:.0f}, Ã‰tapes = {steps}")

avg_score_sac = sum(scores_sac) / len(scores_sac)
print(f"   âœ… Score moyen SAC : {avg_score_sac:.1f}")

env_pendulum.close()

print("\n" + "=" * 70)
print("âœ… TESTS TERMINÃ‰S !")
print("=" * 70)
print("\nðŸ’¡ RÃ©sumÃ© :")
print("   - PPO et DQN : Ã‰quilibrer un bÃ¢ton sur CartPole")
print("   - SAC : Faire tourner un pendule")
print("\n   Les fenÃªtres que vous venez de voir = l'IA en action ! ðŸŽ®")
print("=" * 70)

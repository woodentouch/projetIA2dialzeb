# Check-it! - D√©tecteur de D√©sinformation par RoBERTa

Ce projet impl√©mente un syst√®me automatis√© de d√©tection de d√©sinformation (fake news) utilisant un mod√®le **RoBERTa fine-tun√©** sur des donn√©es multilingues. Le verdict de v√©rit√© est d√©termin√© uniquement par le mod√®le ML (pas par agr√©gation de sources). Les sources web sont r√©cup√©r√©es pour **transparence** et **analyse de manipulation** uniquement si l'affirmation est d√©tect√©e comme fausse.

## Groupe 31

### Marilson SOUZA
### Brenda KOUNDJO
### Xiner GU

## Pr√©requis

- Python 3.8 ou sup√©rieur
- Cl√©s API OpenAI (requise)
- Cl√© API SerpAPI (optionnelle, pour recherche Google)

## Installation

1. Cr√©er un environnement virtuel :
   ```bash
   python -m venv venv
   venv\Scripts\activate  # Sur Windows
   ```

2. Installer les d√©pendances :
   ```bash
   pip install -r requirements.txt
   ```

### Fine-tuner RoBERTa sur vos donn√©es

Une fois le CSV pr√™t (`text`,`label` avec labels FAKE/REAL), lancez l'entra√Ænement local :

```bash
python train_roberta_fakenews.py --data_path fake_news_dataset_multilang.csv \
  --model_name roberta-base \
  --output_dir models/roberta-fake-news \
  --max_length 256 \
  --batch_size 16 \
  --epochs 5 \
  --seed 42
```

- Le DataLoader est reshuffle √† chaque epoch pour √©viter les clusters par langue.
- Un split stratifi√© validation est appliqu√© (`test_size=0.15`).
- La meilleure checkpoint (selon `f1` sur FAKE) est sauvegard√©e dans `--output_dir`.

Pour utiliser le mod√®le fine-tun√© dans l'app :

```bash
set FAKE_NEWS_MODEL_PATH=models/roberta-fake-news  # Windows
export FAKE_NEWS_MODEL_PATH=models/roberta-fake-news # macOS/Linux
```

Vous pouvez ajuster les seuils via `FAKE_NEWS_FAKE_THRESHOLD` et `FAKE_NEWS_REAL_THRESHOLD` (par d√©faut 0.6) ainsi que `FAKE_NEWS_MAX_LENGTH`.

3. Configurer les cl√©s API :
   √âditer `.env` avec vos cl√©s API :
   - `OPENAI_API_KEY` (requis)
   - `SERPAPI_API_KEY` (optionnel, utilise DuckDuckGo sinon)
   - `OPENAI_MODEL` (optionnel, d√©faut: `gpt-4o-mini`)

## Utilisation

### Interface web
1. Lancer l'application Flask :
   ```bash
   flask --app app run --debug
   ```
2. Ouvrir http://127.0.0.1:5000 dans votre navigateur
3. Coller une affirmation ou un texte contenant plusieurs affirmations
4. Cliquer sur "V√©rifier" pour lancer l'analyse
 
### Fonctionnalit√©s

#### Pipeline de v√©rification
1. **Verdict par RoBERTa fine-tun√©** : Mod√®le RoBERTa entra√Æn√© sur donn√©es multilingues (FAKE/REAL) avec shuffle per epoch et stratification. Verdict unique et d√©terministe, seuils configurables (d√©faut 0.6). **Pas d'agr√©gation de sources** ‚Äî le mod√®le d√©cide seul.

2. **Sources pour transparence** : Recherche web (SerpAPI ou DuckDuckGo) avec r√©cup√©ration du contenu des pages (jusqu'√† 6 sources). Filtrage des domaines bloqu√©s (Reddit, Medium, Quora, etc.). Sources tri√©es par cr√©dibilit√©, affich√©es uniquement au clic "üîç Localiser les sources".

3. **Sources filtr√©es par verdict** :
  - Si RoBERTa dit **FAKE** ‚Üí affiche uniquement sources qui *contredisent*
  - Si RoBERTa dit **REAL** ‚Üí affiche uniquement sources qui *supportent*

4. **Analyse de manipulation** (si FAKE d√©tect√©) : Identification de la narrative, audience cible, vecteurs de propagation, ressorts psychologiques, conseils pratiques via "En savoir plus" ‚Üí modal.

5. **√âvaluation de cr√©dibilit√© des sources** (pour transparence uniquement) :
  - Scoring par LLM avec mise en cache persistante
  - Priors manuels (Reuters, AFP, fact-checkers, .gov, .edu)
  - Plafonnement pour r√©seaux sociaux (max 30%)

#### Interface utilisateur
- **Barre de progression anim√©e** pendant l'analyse
- **RoBERTa block** : Verdict (FAKE/REAL/INCONCLUSIVE) avec probabilit√©s fake/real et confiance
- **Bouton "üîç Localiser les sources"** : Affiche sources *pertinentes* au verdict (contrediction si FAKE, support si REAL)
- **R√©sultats color√©s** selon le verdict :
  - Vert = affirmation support√©e
  - Rouge = affirmation contredite
  - Jaune = inconclusif
- **Animation progressive** : affirmations et sources apparaissent une par une
- **Bouton "En savoir plus"** sur affirmations fausses ‚Üí modal d'analyse de d√©sinformation (narrative, audience, vecteurs, protection)
- **D√©tection de propos haineux** (filtrage automatique)

### Remarques d'exploitation

- OpenAI API requis pour **analyse de manipulation** uniquement (si FAKE d√©tect√©)
- RoBERTa fine-tun√© ex√©cut√© localement (transformers) : t√©l√©chargement du mod√®le entra√Æn√© (~500 MB) ou utilisation du checkpoint fourni
- Entra√Ænement du mod√®le : `train_roberta_fakenews.py` avec stratification, shuffle per epoch, validation split 15%
- Cache de cr√©dibilit√© sauvegard√© dans `cred_cache.json` pour √©viter appels API redondants
- SerpAPI recommand√© pour meilleurs r√©sultats de recherche (limite gratuite: 100 recherches/mois)
- BeautifulSoup utilis√© pour extraction de contenu web propre (√©vite snippets tronqu√©s)

## Structure du projet

- `app.py` : Application Flask principale (RoBERTa detection, evidence retrieval, manipulation analysis)
- `train_roberta_fakenews.py` : Script de fine-tuning RoBERTa sur donn√©es CSV (labels FAKE/REAL)
- `templates/index.html` : Interface web avec animations, modal, filtrage sources par verdict
- `requirements.txt` : D√©pendances Python (transformers, torch, pandas, scikit-learn, accelerate, etc.)
- `models/roberta-fake-news/` : Checkpoint du mod√®le fine-tun√© (g√©n√©r√© apr√®s entra√Ænement)
- `.env.example` : Template de configuration (cl√©s API, chemin mod√®le, seuils)
- `fake_news_dataset_multilang.csv` : Donn√©es d'entra√Ænement multilingues (text, label)
- `cred_cache.json` : Cache de cr√©dibilit√© des domaines (g√©n√©r√© automatiquement)

## Configuration avanc√©e

### Constantes cl√©s dans `app.py`
- `TRUSTED_DOMAIN_PRIORS` : Liste des domaines de confiance avec scores manuels
- `DEFAULT_NEUTRAL_PRIOR = 0.45` : Score par d√©faut pour domaines inconnus
- `MIN_CREDIBILITY_INCLUDE = 0.6` : Seuil pour inclusion dans verdict
- `MIN_RELEVANCE = 0.35` : Seuil de pertinence
- `MAX_RESULTS = 6` : Nombre max de sources par affirmation
- `BLOCKED_DOMAINS` : Liste noire (Reddit, Medium, etc.)
- `UGC_DOMAINS` : R√©seaux sociaux (plafonn√©s √† 30%)
- `MAX_CRED_FOR_UGC = 0.3` : Plafond pour contenu g√©n√©r√© par utilisateurs

## Endpoints API

### `POST /api/verify`
Analyse une ou plusieurs affirmations.

**Corps de requ√™te :**
```json
{ "text": "Le vaccin COVID r√©duit les hospitalisations de 60%" }
```

**R√©ponse :**
```json
{
  "claims": [
    {
      "claim": "Le vaccin COVID r√©duit les hospitalisations de 60%",
      "verdict": "support",
      "stance_scores": {
        "support": 0.85,
        "contradict": 0.10,
        "inconclusive": 0.05
      },
      "evidence": [
        {
          "source": "who.int",
          "url": "https://...",
          "snippet": "...",
          "stance": "support",
          "credibility": 0.9,
          "confidence": 0.85,
          "relevance": 0.92,
          "used_in_score": true
        }
      ],
      "updated_at": "2026-01-03T19:45:00Z",
      "manipulation_analysis": null
    }
  ]
}
```

### `GET /`
Interface web simple avec textarea et bouton de v√©rification.

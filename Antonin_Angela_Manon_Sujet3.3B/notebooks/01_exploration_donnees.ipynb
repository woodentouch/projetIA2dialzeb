{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ Imports rÃ©ussis !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b713de",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Chargement des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les datasets\n",
    "train_df = pd.read_csv('../data/processed/train.csv')\n",
    "val_df = pd.read_csv('../data/processed/val.csv')\n",
    "test_df = pd.read_csv('../data/processed/test.csv')\n",
    "\n",
    "print(f\"ðŸ“ DonnÃ©es chargÃ©es :\")\n",
    "print(f\"   Train : {len(train_df)} exemples\")\n",
    "print(f\"   Val   : {len(val_df)} exemples\")\n",
    "print(f\"   Test  : {len(test_df)} exemples\")\n",
    "print(f\"   Total : {len(train_df) + len(val_df) + len(test_df)} exemples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd31079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AperÃ§u des donnÃ©es\n",
    "print(\"\\nðŸ“‹ AperÃ§u des 5 premiÃ¨res lignes :\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d95dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informations sur les colonnes\n",
    "print(\"\\nâ„¹ï¸ Informations sur le dataset :\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91954e9b",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Statistiques Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df62e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longueur des textes\n",
    "train_df['text_length'] = train_df['text'].str.len()\n",
    "train_df['word_count'] = train_df['text'].str.split().str.len()\n",
    "\n",
    "print(\"ðŸ“ Statistiques sur les textes :\")\n",
    "print(f\"\\nLongueur en caractÃ¨res :\")\n",
    "print(train_df['text_length'].describe())\n",
    "print(f\"\\nNombre de mots :\")\n",
    "print(train_df['word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2950cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des labels\n",
    "print(\"\\nðŸ·ï¸ Distribution des labels :\\n\")\n",
    "\n",
    "print(\"Ã‰motions :\")\n",
    "print(train_df['emotion'].value_counts())\n",
    "\n",
    "print(\"\\nSentiment :\")\n",
    "sentiment_map = {0: 'NÃ©gatif', 1: 'Neutre', 2: 'Positif'}\n",
    "print(train_df['sentiment'].map(sentiment_map).value_counts())\n",
    "\n",
    "print(\"\\nIronie :\")\n",
    "irony_map = {0: 'Non-ironique', 1: 'Ironique'}\n",
    "print(train_df['is_ironic'].map(irony_map).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfad9df",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b936c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des longueurs de texte\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogramme des longueurs\n",
    "axes[0].hist(train_df['text_length'], bins=50, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Distribution des Longueurs de Texte (caractÃ¨res)', fontsize=14)\n",
    "axes[0].set_xlabel('Longueur (caractÃ¨res)')\n",
    "axes[0].set_ylabel('FrÃ©quence')\n",
    "axes[0].axvline(train_df['text_length'].mean(), color='red', linestyle='--', label=f'Moyenne: {train_df[\"text_length\"].mean():.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Histogramme du nombre de mots\n",
    "axes[1].hist(train_df['word_count'], bins=30, color='lightgreen', edgecolor='black')\n",
    "axes[1].set_title('Distribution du Nombre de Mots', fontsize=14)\n",
    "axes[1].set_xlabel('Nombre de mots')\n",
    "axes[1].set_ylabel('FrÃ©quence')\n",
    "axes[1].axvline(train_df['word_count'].mean(), color='red', linestyle='--', label=f'Moyenne: {train_df[\"word_count\"].mean():.0f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des classes (3 tÃ¢ches)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Ã‰motions\n",
    "emotion_counts = train_df['emotion'].value_counts()\n",
    "axes[0].bar(emotion_counts.index, emotion_counts.values, color='coral')\n",
    "axes[0].set_title('Distribution des Ã‰motions', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Ã‰motion')\n",
    "axes[0].set_ylabel('Nombre d\\'exemples')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Sentiment\n",
    "sentiment_counts = train_df['sentiment'].map(sentiment_map).value_counts()\n",
    "axes[1].bar(sentiment_counts.index, sentiment_counts.values, color='skyblue')\n",
    "axes[1].set_title('Distribution des Sentiments', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Sentiment')\n",
    "axes[1].set_ylabel('Nombre d\\'exemples')\n",
    "\n",
    "# Ironie\n",
    "irony_counts = train_df['is_ironic'].map(irony_map).value_counts()\n",
    "axes[2].bar(irony_counts.index, irony_counts.values, color='lightgreen')\n",
    "axes[2].set_title('Distribution de l\\'Ironie', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Type')\n",
    "axes[2].set_ylabel('Nombre d\\'exemples')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844f4e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camembert (pie chart) pour mieux voir les proportions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Ã‰motions\n",
    "axes[0].pie(emotion_counts.values, labels=emotion_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Proportion des Ã‰motions', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Sentiment\n",
    "axes[1].pie(sentiment_counts.values, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff','#99ff99'])\n",
    "axes[1].set_title('Proportion des Sentiments', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Ironie\n",
    "axes[2].pie(irony_counts.values, labels=irony_counts.index, autopct='%1.1f%%', startangle=90, colors=['#ffcc99', '#ff9999'])\n",
    "axes[2].set_title('Proportion de l\\'Ironie', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd58858",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Analyse des DÃ©sÃ©quilibres de Classes\n",
    "\n",
    "**Important** : Les dÃ©sÃ©quilibres peuvent affecter les performances du modÃ¨le !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le dÃ©sÃ©quilibre\n",
    "print(\"âš–ï¸ Analyse des dÃ©sÃ©quilibres :\\n\")\n",
    "\n",
    "# Ã‰motions\n",
    "emotion_balance = emotion_counts.max() / emotion_counts.min()\n",
    "print(f\"Ã‰motions :\")\n",
    "print(f\"  Ratio max/min : {emotion_balance:.2f}x\")\n",
    "if emotion_balance > 3:\n",
    "    print(f\"  âš ï¸ DÃ©sÃ©quilibre important ! ConsidÃ©rer class weighting ou oversampling\")\n",
    "else:\n",
    "    print(f\"  âœ“ DÃ©sÃ©quilibre acceptable\")\n",
    "\n",
    "# Sentiment\n",
    "sentiment_balance = sentiment_counts.max() / sentiment_counts.min()\n",
    "print(f\"\\nSentiment :\")\n",
    "print(f\"  Ratio max/min : {sentiment_balance:.2f}x\")\n",
    "if sentiment_balance > 3:\n",
    "    print(f\"  âš ï¸ DÃ©sÃ©quilibre important !\")\n",
    "else:\n",
    "    print(f\"  âœ“ DÃ©sÃ©quilibre acceptable\")\n",
    "\n",
    "# Ironie\n",
    "irony_balance = irony_counts.max() / irony_counts.min()\n",
    "print(f\"\\nIronie :\")\n",
    "print(f\"  Ratio max/min : {irony_balance:.2f}x\")\n",
    "if irony_balance > 2:\n",
    "    print(f\"  âš ï¸ DÃ©sÃ©quilibre important !\")\n",
    "else:\n",
    "    print(f\"  âœ“ DÃ©sÃ©quilibre acceptable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca6fa41",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Exemples de Textes par CatÃ©gorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb3be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher des exemples pour chaque Ã©motion\n",
    "print(\"ðŸ“ Exemples de textes par Ã©motion :\\n\")\n",
    "\n",
    "for emotion in train_df['emotion'].unique():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Ã‰MOTION : {emotion.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    examples = train_df[train_df['emotion'] == emotion].sample(n=min(3, len(train_df[train_df['emotion'] == emotion])))\n",
    "    \n",
    "    for idx, row in examples.iterrows():\n",
    "        print(f\"\\n  â€¢ {row['text']}\")\n",
    "        print(f\"    â†’ Sentiment: {sentiment_map[row['sentiment']]}, Ironie: {irony_map[row['is_ironic']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb54c0",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ CorrÃ©lations entre les TÃ¢ches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser la corrÃ©lation entre Ã©motion et sentiment\n",
    "print(\"ðŸ”— CorrÃ©lations Ã‰motion â†” Sentiment :\\n\")\n",
    "\n",
    "cross_tab = pd.crosstab(train_df['emotion'], train_df['sentiment'].map(sentiment_map))\n",
    "print(cross_tab)\n",
    "\n",
    "# Visualiser\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cross_tab, annot=True, fmt='d', cmap='YlOrRd')\n",
    "plt.title('Heatmap : Ã‰motion vs Sentiment', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Ã‰motion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bac6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser la corrÃ©lation entre ironie et sentiment\n",
    "print(\"\\nðŸ”— CorrÃ©lations Ironie â†” Sentiment :\\n\")\n",
    "\n",
    "cross_tab2 = pd.crosstab(train_df['is_ironic'].map(irony_map), train_df['sentiment'].map(sentiment_map))\n",
    "print(cross_tab2)\n",
    "\n",
    "# Visualiser\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.heatmap(cross_tab2, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Heatmap : Ironie vs Sentiment', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Ironie')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac218bfd",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Analyse de la Ponctuation et Emojis\n",
    "\n",
    "**Important** : Les emojis et la ponctuation sont cruciaux pour l'analyse de sentiment !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0503532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Compter les emojis\n",
    "def count_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return len(emoji_pattern.findall(text))\n",
    "\n",
    "train_df['emoji_count'] = train_df['text'].apply(count_emojis)\n",
    "train_df['exclamation_count'] = train_df['text'].str.count('!')\n",
    "train_df['question_count'] = train_df['text'].str.count('\\?')\n",
    "\n",
    "print(\"ðŸ˜Š Statistiques sur les emojis et ponctuation :\\n\")\n",
    "print(f\"Textes avec emojis : {(train_df['emoji_count'] > 0).sum()} ({(train_df['emoji_count'] > 0).sum() / len(train_df) * 100:.1f}%)\")\n",
    "print(f\"Textes avec '!' : {(train_df['exclamation_count'] > 0).sum()} ({(train_df['exclamation_count'] > 0).sum() / len(train_df) * 100:.1f}%)\")\n",
    "print(f\"Textes avec '?' : {(train_df['question_count'] > 0).sum()} ({(train_df['question_count'] > 0).sum() / len(train_df) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2413cb85",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Sauvegarde du Rapport d'Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6045152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er un rapport rÃ©capitulatif\n",
    "report = {\n",
    "    'dataset_size': {\n",
    "        'train': len(train_df),\n",
    "        'val': len(val_df),\n",
    "        'test': len(test_df),\n",
    "        'total': len(train_df) + len(val_df) + len(test_df)\n",
    "    },\n",
    "    'text_statistics': {\n",
    "        'avg_length_chars': float(train_df['text_length'].mean()),\n",
    "        'avg_words': float(train_df['word_count'].mean()),\n",
    "        'max_length': int(train_df['text_length'].max()),\n",
    "        'min_length': int(train_df['text_length'].min())\n",
    "    },\n",
    "    'class_distribution': {\n",
    "        'emotions': emotion_counts.to_dict(),\n",
    "        'sentiment': sentiment_counts.to_dict(),\n",
    "        'irony': irony_counts.to_dict()\n",
    "    },\n",
    "    'class_balance': {\n",
    "        'emotion_ratio': float(emotion_balance),\n",
    "        'sentiment_ratio': float(sentiment_balance),\n",
    "        'irony_ratio': float(irony_balance)\n",
    "    },\n",
    "    'special_features': {\n",
    "        'texts_with_emojis': int((train_df['emoji_count'] > 0).sum()),\n",
    "        'texts_with_exclamation': int((train_df['exclamation_count'] > 0).sum()),\n",
    "        'texts_with_question': int((train_df['question_count'] > 0).sum())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Sauvegarder\n",
    "with open('../data/exploration_report.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"âœ… Rapport d'exploration sauvegardÃ© dans 'data/exploration_report.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31ebc2",
   "metadata": {},
   "source": [
    "## âœ… Conclusions\n",
    "\n",
    "**Points clÃ©s identifiÃ©s** :\n",
    "\n",
    "1. **Taille du dataset** : Suffisant pour un entraÃ®nement initial (~1500 exemples)\n",
    "2. **DÃ©sÃ©quilibres** : Ã€ surveiller, peut nÃ©cessiter class weighting\n",
    "3. **Longueur des textes** : Courts Ã  moyens (typique des tweets/commentaires)\n",
    "4. **CaractÃ©ristiques spÃ©ciales** : PrÃ©sence d'emojis et ponctuation expressive\n",
    "\n",
    "**Prochaines Ã©tapes** :\n",
    "- âœ… Phase 1 : Exploration â†’ **TERMINÃ‰E**\n",
    "- ðŸ”œ Phase 2 : Preprocessing (nettoyage, tokenization)\n",
    "- ðŸ”œ Phase 3 : ModÃ¨le baseline\n",
    "- ðŸ”œ Phase 4 : CamemBERT multi-tÃ¢ches"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

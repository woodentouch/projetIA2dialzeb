"""
Script de t√©l√©chargement et pr√©paration des datasets fran√ßais
Utilise Allocin√© (HuggingFace) pour le sentiment et des donn√©es synth√©tiques pour le reste.
"""

import os
import pandas as pd
import numpy as np
from datasets import load_dataset
from sklearn.model_selection import train_test_split
import json

# Configuration
np.random.seed(42)
DATA_DIR = "data"
RAW_DIR = os.path.join(DATA_DIR, "raw")
PROCESSED_DIR = os.path.join(DATA_DIR, "processed")

os.makedirs(RAW_DIR, exist_ok=True)
os.makedirs(PROCESSED_DIR, exist_ok=True)

print("=" * 70)
print("T√âL√âCHARGEMENT DES DATASETS FRAN√áAIS")
print("=" * 70)

def get_allocine_data():
    print("\nüì• 1. T√©l√©chargement du dataset Allocin√© (Sentiment)...")
    try:
        dataset = load_dataset("allocine")
        
        # Subsampling pour aller vite
        train_df = pd.DataFrame(dataset['train']).sample(n=2000, random_state=42)
        val_df = pd.DataFrame(dataset['validation']).sample(n=500, random_state=42)
        test_df = pd.DataFrame(dataset['test']).sample(n=500, random_state=42)
        
        # Mapping: 0=neg, 1=pos -> 0=neg, 2=pos (1=neutre)
        def map_sentiment(x):
            return 0 if x == 0 else 2
            
        for df in [train_df, val_df, test_df]:
            df['sentiment_label'] = df['label'].apply(map_sentiment)
            df['text'] = df['review']
            df['emotion_label'] = -1
            df['irony_label'] = -1
            
        return train_df, val_df, test_df
    except Exception as e:
        print(f"Erreur lors du chargement d'Allocin√©: {e}")
        print("Utilisation de donn√©es synth√©tiques pour Allocin√©.")
        return None, None, None

def get_synthetic_data():
    print("\nüì• 2. G√©n√©ration de donn√©es synth√©tiques (√âmotions/Ironie)...")
    
    # --- EMOTIONS ---
    emotion_examples = {
        'joie': ["Je suis trop content !", "C'est g√©nial !", "J'adore √ßa ‚ù§Ô∏è", "Quelle bonne nouvelle !"],
        'tristesse': ["Je suis triste üò¢", "C'est d√©primant", "Je me sens seul", "Quelle d√©ception"],
        'colere': ["√áa m'√©nerve ! üò°", "C'est inadmissible", "Je suis furieux", "N'importe quoi !"],
        'peur': ["J'ai peur üò®", "C'est effrayant", "Je suis angoiss√©", "Au secours !"],
        'surprise': ["Oh ! Vraiment ? üòÆ", "Je ne m'y attendais pas", "Incroyable !", "Wow !"],
        'degout': ["C'est d√©go√ªtant ü§¢", "Beurk", "J'ai la naus√©e", "C'est immonde"],
        'neutre': ["Il fait beau.", "Je vais au travail.", "Le ciel est bleu.", "J'ai mang√© une pomme."]
    }
    
    emotion_mapping = {'joie': 0, 'tristesse': 1, 'colere': 2, 'peur': 3, 'surprise': 4, 'degout': 5, 'neutre': 6}
    
    data = []
    for emo, texts in emotion_examples.items():
        for t in texts:
            for _ in range(20): # Augmenter la taille
                data.append({
                    'text': t,
                    'emotion_label': emotion_mapping[emo],
                    'sentiment_label': -1, # On pourrait inf√©rer mais restons simple
                    'irony_label': -1
                })
                
    # --- IRONIE ---
    ironic = ["Super, il pleut encore ! üôÑ", "G√©nial ce bouchon...", "Merci pour ce cadeau inutile.", "Bravo champion !"]
    not_ironic = ["Il pleut aujourd'hui.", "Il y a des bouchons.", "Merci pour le cadeau.", "Bravo pour ta victoire."]
    
    for t in ironic:
        for _ in range(25):
            data.append({'text': t, 'emotion_label': -1, 'sentiment_label': -1, 'irony_label': 1})
            
    for t in not_ironic:
        for _ in range(25):
            data.append({'text': t, 'emotion_label': -1, 'sentiment_label': -1, 'irony_label': 0})
            
    df = pd.DataFrame(data)
    train, test = train_test_split(df, test_size=0.2, random_state=42)
    train, val = train_test_split(train, test_size=0.2, random_state=42)
    
    return train, val, test

def main():
    # 1. Allocin√©
    train_allocine, val_allocine, test_allocine = get_allocine_data()
    
    # 2. Synthetic
    train_syn, val_syn, test_syn = get_synthetic_data()
    
    # 3. Merge
    cols = ['text', 'emotion_label', 'sentiment_label', 'irony_label']
    
    if train_allocine is not None:
        train_final = pd.concat([train_allocine[cols], train_syn[cols]])
        val_final = pd.concat([val_allocine[cols], val_syn[cols]])
        test_final = pd.concat([test_allocine[cols], test_syn[cols]])
    else:
        train_final = train_syn[cols]
        val_final = val_syn[cols]
        test_final = test_syn[cols]
        
    # Shuffle
    train_final = train_final.sample(frac=1, random_state=42).reset_index(drop=True)
    val_final = val_final.sample(frac=1, random_state=42).reset_index(drop=True)
    test_final = test_final.sample(frac=1, random_state=42).reset_index(drop=True)
    
    print(f"\n‚úÖ Dataset final g√©n√©r√© :")
    print(f"   Train: {len(train_final)}")
    print(f"   Val:   {len(val_final)}")
    print(f"   Test:  {len(test_final)}")
    
    train_final.to_csv(os.path.join(PROCESSED_DIR, "train.csv"), index=False)
    val_final.to_csv(os.path.join(PROCESSED_DIR, "val.csv"), index=False)
    test_final.to_csv(os.path.join(PROCESSED_DIR, "test.csv"), index=False)
    
    # Stats
    stats = {
        'train_size': len(train_final),
        'val_size': len(val_final),
        'test_size': len(test_final)
    }
    with open(os.path.join(DATA_DIR, "dataset_stats.json"), 'w') as f:
        json.dump(stats, f, indent=2)

if __name__ == "__main__":
    main()

"""
Script pour appliquer le preprocessing aux datasets et afficher des statistiques
"""

import os
import pandas as pd
import sys

# Ajouter le rÃ©pertoire parent au path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from data.preprocessing import preprocess_dataset, clean_text, get_text_stats


def main():
    print("=" * 70)
    print("PREPROCESSING DES DATASETS")
    print("=" * 70)
    
    # Chemins
    data_dir = "data/processed"
    
    # Charger les datasets
    print("\nğŸ“‚ Chargement des donnÃ©es...")
    train_df = pd.read_csv(os.path.join(data_dir, "train.csv"))
    val_df = pd.read_csv(os.path.join(data_dir, "val.csv"))
    test_df = pd.read_csv(os.path.join(data_dir, "test.csv"))
    
    print(f"   âœ“ Train: {len(train_df)} exemples")
    print(f"   âœ“ Val:   {len(val_df)} exemples")
    print(f"   âœ“ Test:  {len(test_df)} exemples")
    
    # =============================================================================
    # PREPROCESSING TRAIN
    # =============================================================================
    print("\n" + "=" * 70)
    print("1ï¸âƒ£ PREPROCESSING TRAIN SET")
    print("=" * 70)
    
    train_df = preprocess_dataset(train_df)
    
    # Afficher quelques exemples
    print("\nğŸ“‹ Exemples de textes nettoyÃ©s (Train) :\n")
    for i in range(min(5, len(train_df))):
        row = train_df.iloc[i]
        print(f"{i+1}. Original : {row['text'][:80]}...")
        print(f"   NettoyÃ©  : {row['text_clean'][:80]}...")
        print(f"   Ã‰motion  : {row['emotion']}, Sentiment: {row['sentiment']}, Ironie: {row['is_ironic']}")
        print()
    
    # =============================================================================
    # PREPROCESSING VAL
    # =============================================================================
    print("\n" + "=" * 70)
    print("2ï¸âƒ£ PREPROCESSING VALIDATION SET")
    print("=" * 70)
    
    val_df = preprocess_dataset(val_df)
    
    # =============================================================================
    # PREPROCESSING TEST
    # =============================================================================
    print("\n" + "=" * 70)
    print("3ï¸âƒ£ PREPROCESSING TEST SET")
    print("=" * 70)
    
    test_df = preprocess_dataset(test_df)
    
    # =============================================================================
    # STATISTIQUES COMPARATIVES
    # =============================================================================
    print("\n" + "=" * 70)
    print("ğŸ“Š STATISTIQUES COMPARATIVES")
    print("=" * 70)
    
    print("\nğŸ” Longueur des textes :")
    print(f"   Train : Moy={train_df['text_length'].mean():.1f}, "
          f"Min={train_df['text_length'].min()}, Max={train_df['text_length'].max()}")
    print(f"   Val   : Moy={val_df['text_length'].mean():.1f}, "
          f"Min={val_df['text_length'].min()}, Max={val_df['text_length'].max()}")
    print(f"   Test  : Moy={test_df['text_length'].mean():.1f}, "
          f"Min={test_df['text_length'].min()}, Max={test_df['text_length'].max()}")
    
    print("\nğŸ˜Š PrÃ©sence d'emojis :")
    print(f"   Train : {(train_df['emoji_count'] > 0).sum()} textes ({(train_df['emoji_count'] > 0).sum() / len(train_df) * 100:.1f}%)")
    print(f"   Val   : {(val_df['emoji_count'] > 0).sum()} textes ({(val_df['emoji_count'] > 0).sum() / len(val_df) * 100:.1f}%)")
    print(f"   Test  : {(test_df['emoji_count'] > 0).sum()} textes ({(test_df['emoji_count'] > 0).sum() / len(test_df) * 100:.1f}%)")
    
    print("\nâ— Ponctuation expressive :")
    print(f"   Train : {(train_df['exclamation_count'] > 0).sum()} avec '!' ({(train_df['exclamation_count'] > 0).sum() / len(train_df) * 100:.1f}%)")
    print(f"   Val   : {(val_df['exclamation_count'] > 0).sum()} avec '!' ({(val_df['exclamation_count'] > 0).sum() / len(val_df) * 100:.1f}%)")
    print(f"   Test  : {(test_df['exclamation_count'] > 0).sum()} avec '!' ({(test_df['exclamation_count'] > 0).sum() / len(test_df) * 100:.1f}%)")
    
    # =============================================================================
    # DISTRIBUTION DES CLASSES
    # =============================================================================
    print("\n" + "=" * 70)
    print("ğŸ·ï¸ DISTRIBUTION DES CLASSES")
    print("=" * 70)
    
    print("\nğŸ“Š Ã‰motions (Train) :")
    emotion_dist = train_df['emotion'].value_counts().sort_index()
    for emotion, count in emotion_dist.items():
        print(f"   {emotion:12} : {count:3} ({count/len(train_df)*100:5.1f}%)")
    
    print("\nğŸ“Š Sentiment (Train) :")
    sentiment_map = {0: 'NÃ©gatif', 1: 'Neutre', 2: 'Positif'}
    sentiment_dist = train_df['sentiment'].value_counts().sort_index()
    for sent_id, count in sentiment_dist.items():
        print(f"   {sentiment_map[sent_id]:12} : {count:3} ({count/len(train_df)*100:5.1f}%)")
    
    print("\nğŸ“Š Ironie (Train) :")
    irony_map = {0: 'Non-ironique', 1: 'Ironique'}
    irony_dist = train_df['is_ironic'].value_counts().sort_index()
    for irony_id, count in irony_dist.items():
        print(f"   {irony_map[irony_id]:14} : {count:3} ({count/len(train_df)*100:5.1f}%)")
    
    # =============================================================================
    # SAUVEGARDE
    # =============================================================================
    print("\n" + "=" * 70)
    print("ğŸ’¾ SAUVEGARDE DES DONNÃ‰ES PREPROCESSÃ‰ES")
    print("=" * 70)
    
    # Sauvegarder avec les colonnes nettoyÃ©es
    train_df.to_csv(os.path.join(data_dir, "train_preprocessed.csv"), index=False)
    val_df.to_csv(os.path.join(data_dir, "val_preprocessed.csv"), index=False)
    test_df.to_csv(os.path.join(data_dir, "test_preprocessed.csv"), index=False)
    
    print(f"\n   âœ“ {data_dir}/train_preprocessed.csv")
    print(f"   âœ“ {data_dir}/val_preprocessed.csv")
    print(f"   âœ“ {data_dir}/test_preprocessed.csv")
    
    # =============================================================================
    # RÃ‰SUMÃ‰ FINAL
    # =============================================================================
    print("\n" + "=" * 70)
    print("âœ… PREPROCESSING TERMINÃ‰ !")
    print("=" * 70)
    
    print(f"\nğŸ“ˆ RÃ©sumÃ© :")
    print(f"   â€¢ {len(train_df)} exemples d'entraÃ®nement preprocessÃ©s")
    print(f"   â€¢ {len(val_df)} exemples de validation preprocessÃ©s")
    print(f"   â€¢ {len(test_df)} exemples de test preprocessÃ©s")
    print(f"   â€¢ Emojis prÃ©servÃ©s : âœ“")
    print(f"   â€¢ Ponctuation prÃ©servÃ©e : âœ“")
    print(f"   â€¢ URLs supprimÃ©es : âœ“")
    print(f"   â€¢ Mentions supprimÃ©es : âœ“")
    
    print(f"\nğŸ¯ Prochaine Ã©tape :")
    print(f"   â€¢ CrÃ©er le modÃ¨le baseline (TF-IDF + Logistic Regression)")
    print("=" * 70)


if __name__ == "__main__":
    main()
